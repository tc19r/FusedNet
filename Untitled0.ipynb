{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMWNx5Ni+WnUlMpWm9V5bu4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tc19r/FusedNet/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LHGLuO2cP4W5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This note book is to address the memory problem.\n",
        "The guess is that, the static graph of the triangular solve take up too much meomry. Using Np to get the inverse directly. However, The final form may still take up too much memory. I wonder how did the sklearn module calculated the energy.But again, that sklearn method do not build static graphs. \n",
        "\n",
        "https://stackoverflow.com/questions/110259/which-python-memory-profiler-is-recommended\n",
        "This link, although not perfect, is better then the line by line test. At least, it is easier to see which line clogged the memory.\n",
        "\n",
        "increasing the shrink factor to 100, installing profiling tool."
      ],
      "metadata": {
        "id": "O_Ktx81WP5PU"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Rat8gbzKZRqA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from memory_profiler import profile\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "@profile\n",
        "def run():\n",
        "    #Load\n",
        "    X=np.empty([0,34])\n",
        "    rootpath='./'\n",
        "    for root, dirs, files in os.walk(rootpath):\n",
        "         for filename in [fi for fi in files if fi.endswith(\".pf\")]:\n",
        "             pf=np.fromfile(filename)\n",
        "             pf=pf.reshape(int(len(pf)/34),34)\n",
        "             np.random.shuffle(pf)\n",
        "             X=np.vstack([X,pf])\n",
        "             print(pf.shape)\n",
        "             print(filename)\n",
        "    trainset=np.float64(X)\n",
        "\n",
        "    num_classes=400\n",
        "    from sklearn.mixture import GaussianMixture\n",
        "    gm = GaussianMixture(n_components=num_classes, random_state=0,warm_start=True,max_iter=10)\n",
        "    dataset=trainset[:,0:8]\n",
        "    #Run\n",
        "    shrink=100\n",
        "    indexes=np.random.choice(dataset.shape[0], int(np.floor(dataset.shape[0]/100)), replace=False)\n",
        "    x_batch_train=trainset[indexes,:]\n",
        "    #Hyper parameters \n",
        "    learningrate,lambda1,lambda2=0.0003,1.5e-2,3e-4\n",
        "    epochs = 50\n",
        "    rootpath=\"./\"\n",
        "    num_classes=400\n",
        "    Centers_Lengths_dimension=4\n",
        "    fibs_input_dim=30\n",
        "    dim_fib=30\n",
        "    dim_ctnl=4\n",
        "    recon_dim=fibs_input_dim\n",
        "    inputs_center_and_length = tf.keras.Input(shape=(Centers_Lengths_dimension,))\n",
        "    inputs_fibs_on_ball = tf.keras.Input(shape=(fibs_input_dim,))\n",
        "    encoding_dim = 4\n",
        "    \n",
        "    def getmodel():\n",
        "        encoder=keras.layers.Dense(16, activation='tanh')(inputs_fibs_on_ball)\n",
        "        encoder=keras.layers.Dense(16, activation='tanh')(encoder)\n",
        "        encoder=keras.layers.Dense(8, activation='tanh')(encoder)\n",
        "        encoder=keras.layers.Dense(4, activation='tanh')(encoder)\n",
        "        encoder=keras.layers.Dense(encoding_dim, activation='tanh',name=\"feature\")(encoder)\n",
        "        encoder=keras.Model(inputs=inputs_fibs_on_ball, outputs=encoder)\n",
        "        #define decoder network:\n",
        "\n",
        "        decoder=keras.layers.Dense(4,activation='tanh')(encoder.outputs[0])\n",
        "        decoder=keras.layers.Dense(8, activation='tanh')(decoder)\n",
        "        #decoder = keras.layers.Dropout(0.25)(decoder)\n",
        "        decoder=keras.layers.Dense(16,activation='tanh')(decoder)\n",
        "        #decoder = keras.layers.Dropout(0.25)(decoder)\n",
        "        decoder=keras.layers.Dense(16,activation='tanh')(decoder)\n",
        "        decoder=keras.layers.Dense(recon_dim,activation='linear')(decoder)\n",
        "        decoder=keras.Model(inputs=encoder.inputs, outputs=decoder)\n",
        "        #===\n",
        "        combined = concatenate([decoder.output, encoder.output,inputs_center_and_length,],axis=1)\n",
        "        fusednet = keras.Model(inputs=[inputs_fibs_on_ball,inputs_center_and_length],outputs=combined)\n",
        "        feature_extractor = keras.Model(\n",
        "           inputs=inputs_fibs_on_ball,\n",
        "           outputs=fusednet.get_layer(name=\"feature\").output,\n",
        "        )\n",
        "        return fusednet,feature_extractor,\n",
        "    fusednet,feature_extractor = getmodel()\n",
        "    \n",
        "    model=fusednet\n",
        "    with tf.GradientTape() as tape:\n",
        "        y_pred = model([x_batch_train[:,0:dim_fib],x_batch_train[:,dim_fib:dim_fib+dim_ctnl]], training=True)\n",
        "    z = y_pred[:,recon_dim:]\n",
        "    gm.fit(z)\n",
        "    gamma = gm.predict_proba(z)\n",
        "    gamma_sum = tf.reduce_sum(gamma, axis=0)\n",
        "    phi = tf.reduce_mean(gamma, axis=0)\n",
        "    mu = gm.means_\n",
        "    Sigma = gm.covariances_\n",
        "    n_features = z.shape[1]\n",
        "    min_vals = tf.linalg.diag(tf.ones(n_features, dtype=tf.float64)) * 1e-6\n",
        "    z_centered = z[:, None, :] - mu[None, :, :]"
      ],
      "metadata": {
        "id": "88QZwFywZUkp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Jupyter(Ipython) seems to run into loading issue, the load function can not be edited, Mprun is not updating its function.\n",
        "I tried restarting the session, reload memory profiler, changing the function name, nothing work.\n"
      ],
      "metadata": {
        "id": "P6-tQQE4TqZj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to ciumfance this issue, here we try to use the function decorator. We first decorate the corresponding segment of code with the @profile decorator, and then call them out in the __main__ entrance. This type of coding style is more ellucidated and I see a benefit of learning it."
      ],
      "metadata": {
        "id": "2sgQz9ozT58z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    load()\n",
        "    run()"
      ],
      "metadata": {
        "id": "77rq5rRrUaN8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "However, this type of programming runs into the global variable issue. I guess the better solution is to use class-based programming. Inside your load()/run() functions,you intiate certain class. But wait, you still need to pass the class handles all around the places.Hmmm, but when you work on the level of a subsegment, you are bund to loss the scope of others."
      ],
      "metadata": {
        "id": "9twEpwXeVxLQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://stackoverflow.com/questions/11543297/make-all-variables-in-a-python-function-global\n",
        "Save for later.\n"
      ],
      "metadata": {
        "id": "f-Sge6zRTwm2"
      }
    }
  ]
}